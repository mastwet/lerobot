<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="media/lerobot-logo-thumbnail.png">
    <source media="(prefers-color-scheme: light)" srcset="media/lerobot-logo-thumbnail.png">
    <img alt="LeRobot, Hugging Face Robotics Library" src="media/lerobot-logo-thumbnail.png" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<div align="center">

[![Tests](https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml/badge.svg?branch=main)](https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml?query=branch%3Amain)
[![Coverage](https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO)](https://codecov.io/gh/huggingface/lerobot)
[![Python versions](https://img.shields.io/pypi/pyversions/lerobot)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/huggingface/lerobot/blob/main/LICENSE)
[![Status](https://img.shields.io/pypi/status/lerobot)](https://pypi.org/project/lerobot/)
[![Version](https://img.shields.io/pypi/v/lerobot)](https://pypi.org/project/lerobot/)
[![Examples](https://img.shields.io/badge/Examples-green.svg)](https://github.com/huggingface/lerobot/tree/main/examples)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg)](https://github.com/huggingface/lerobot/blob/main/CODE_OF_CONDUCT.md)
[![Discord](https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat)](https://discord.gg/s3KuuzsPFb)

</div>

<h2 align="center">
    <p><a href="https://github.com/huggingface/lerobot/blob/main/examples/10_use_so100.md">
        Build Your Own SO-100 Robot!</a></p>
</h2>

<div align="center">
  <img src="media/so100/leader_follower.webp?raw=true" alt="SO-100 leader and follower arms" title="SO-100 leader and follower arms" width="50%">

  <p><strong>Meet the SO-100 â€“ Just $110 per arm!</strong></p>
  <p>Train it in minutes with a few simple moves on your laptop.</p>
  <p>Then sit back and watch your creation act autonomously! ğŸ¤¯</p>

  <p><a href="https://github.com/huggingface/lerobot/blob/main/examples/10_use_so100.md">
      Get the full SO-100 tutorial here.</a></p>

  <p>Want to take it to the next level? Make your SO-100 mobile by building LeKiwi!</p>
  <p>Check out the <a href="https://github.com/huggingface/lerobot/blob/main/examples/11_use_lekiwi.md">LeKiwi tutorial</a> and bring your robot to life on wheels.</p>

  <img src="media/lekiwi/kiwi.webp?raw=true" alt="LeKiwi mobile robot" title="LeKiwi mobile robot" width="50%">
</div>

<br/>

<h3 align="center">
    <p>LeRobot: State-of-the-art AI for real-world robotics</p>
</h3>

---


ğŸ¤— LeRobot æ—¨åœ¨ä¸ºç°å®ä¸–ç•Œæœºå™¨äººæŠ€æœ¯æä¾›åŸºäº PyTorch çš„æ¨¡å‹ã€æ•°æ®é›†å’Œå·¥å…·ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é™ä½æœºå™¨äººæŠ€æœ¯çš„å…¥é—¨é—¨æ§›ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½é€šè¿‡å…±äº«æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹å‚ä¸å…¶ä¸­å¹¶ä»ä¸­å—ç›Šã€‚

ğŸ¤— LeRobot åŒ…å«æœ€å…ˆè¿›çš„ç®—æ³•æ–¹æ¡ˆï¼Œè¿™äº›æ–¹æ¡ˆå·²è¢«è¯å®åœ¨ç°å®ä¸–ç•Œä¸­å…·æœ‰è¿ç§»åº”ç”¨ä»·å€¼ï¼Œé‡ç‚¹å…³æ³¨æ¨¡ä»¿å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ æ–¹å‘ã€‚

ğŸ¤— LeRobot ç°å·²æä¾›å¤šç»„é¢„è®­ç»ƒæ¨¡å‹ã€äººå·¥æ¼”ç¤ºæ•°æ®é›†å’Œä»¿çœŸç¯å¢ƒï¼Œæ— éœ€ç»„è£…å®ä½“æœºå™¨äººå³å¯å¿«é€Ÿä¸Šæ‰‹ã€‚æœªæ¥æ•°å‘¨å†…ï¼Œæˆ‘ä»¬å°†æŒç»­æ‰©å±•å¯¹é«˜æ€§ä»·æ¯”å®ä½“æœºå™¨äººçš„æ”¯æŒã€‚

ğŸ¤— LeRobot æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†å‡æ‰˜ç®¡äº Hugging Face ç¤¾åŒºé¡µé¢ï¼š[huggingface.co/lerobot](https://huggingface.co/lerobot)

#### ä»¿çœŸç¯å¢ƒé¢„è®­ç»ƒæ¨¡å‹ç¤ºä¾‹

<table>
  <tr>
    <td><img src="media/gym/aloha_act.gif" width="100%" alt="ALOHAç¯å¢ƒä¸­çš„ACTç­–ç•¥"/></td>
    <td><img src="media/gym/simxarm_tdmpc.gif" width="100%" alt="SimXArmç¯å¢ƒä¸­çš„TDMPCç­–ç•¥"/></td>
    <td><img src="media/gym/pusht_diffusion.gif" width="100%" alt="PushTç¯å¢ƒä¸­çš„Diffusionç­–ç•¥"/></td>
  </tr>
  <tr>
    <td align="center">ALOHAç¯å¢ƒACTç­–ç•¥</td>
    <td align="center">SimXArmç¯å¢ƒTDMPCç­–ç•¥</td>
    <td align="center">PushTç¯å¢ƒDiffusionç­–ç•¥</td>
  </tr>
</table>

### è‡´è°¢å£°æ˜

- æ„Ÿè°¢ Tony Zhaoã€Zipeng Fu ç­‰ç ”ç©¶è€…å¼€æº ACT ç­–ç•¥ã€ALOHA ç¯å¢ƒåŠæ•°æ®é›†ã€‚æˆ‘ä»¬çš„å®ç°åŸºäº [ALOHA](https://tonyzhaozh.github.io/aloha) ä¸ [Mobile ALOHA](https://mobile-aloha.github.io) é¡¹ç›®ã€‚
- æ„Ÿè°¢ Cheng Chiã€Zhenjia Xu ç­‰ç ”ç©¶è€…å¼€æº Diffusion ç­–ç•¥ã€Pusht ç¯å¢ƒä¸æ•°æ®é›†ä»¥åŠ UMI æ•°æ®é›†ã€‚æˆ‘ä»¬çš„å®ç°å‚è€ƒäº† [Diffusion Policy](https://diffusion-policy.cs.columbia.edu) å’Œ [UMI Gripper](https://umi-gripper.github.io) é¡¹ç›®ã€‚
- æ„Ÿè°¢ Nicklas Hansenã€Yunhai Feng ç­‰ç ”ç©¶è€…å¼€æº TDMPC ç­–ç•¥ã€Simxarm ç¯å¢ƒåŠæ•°æ®é›†ã€‚æˆ‘ä»¬çš„å®ç°æºè‡ª [TDMPC](https://github.com/nicklashansen/tdmpc) ä¸ [FOWM](https://www.yunhaifeng.com/FOWM) é¡¹ç›®ã€‚
- æ„Ÿè°¢ Antonio Loquercio å’Œ Ashish Kumar çš„æ—©æœŸæ”¯æŒã€‚
- æ„Ÿè°¢ [Seungjae (Jay) Lee](https://sjlee.cc/)ã€[Mahi Shafiullah](https://mahis.life/) ç­‰ç ”ç©¶è€…å¼€æº [VQ-BeT](https://sjlee.cc/vq-bet/) ç­–ç•¥å¹¶ååŠ©ä»£ç åº“é€‚é…ã€‚è¯¥ç­–ç•¥æ”¹ç¼–è‡ª [VQ-BeT ä»£ç åº“](https://github.com/jayLEE0301/vq_bet_official)ã€‚

## å®‰è£…æŒ‡å—

ä¸‹è½½æºä»£ç ï¼š
```bash
git clone https://github.com/huggingface/lerobot.git
cd lerobot
```

åˆ›å»º Python 3.10 è™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»ï¼ˆæ¨èä½¿ç”¨ [`miniconda`](https://docs.anaconda.com/free/miniconda/index.html)ï¼‰ï¼š
```bash
conda create -y -n lerobot python=3.10
conda activate lerobot
```

ä½¿ç”¨ `miniconda` æ—¶è‹¥ç¼ºå°‘ `ffmpeg` ç»„ä»¶ï¼š
```bash
conda install ffmpeg
```

å®‰è£… ğŸ¤— LeRobotï¼š
```bash
pip install --no-binary=av -e .
```

> **æ³¨æ„ï¼š** å¦‚é‡ç¼–è¯‘é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å®‰è£…é¢å¤–ä¾èµ–ï¼ˆ`cmake`ã€`build-essential` å’Œ `ffmpeg åº“`ï¼‰ã€‚Linux ç³»ç»Ÿè¯·æ‰§è¡Œï¼š
`sudo apt-get install cmake build-essential python-dev pkg-config libavformat-dev libavcodec-dev libavdevice-dev libavutil-dev libswscale-dev libswresample-dev libavfilter-dev pkg-config`ã€‚å…¶ä»–ç³»ç»Ÿå‚è§ï¼š[PyAV ç¼–è¯‘æŒ‡å—](https://pyav.org/docs/develop/overview/installation.html#bring-your-own-ffmpeg)

ä»¿çœŸç¯å¢ƒæ”¯æŒé€šè¿‡é™„åŠ ç»„ä»¶å®‰è£…ï¼š
- [aloha](https://github.com/huggingface/gym-aloha)
- [xarm](https://github.com/huggingface/gym-xarm)
- [pusht](https://github.com/huggingface/gym-pusht)

ä¾‹å¦‚å®‰è£…å« aloha å’Œ pusht ç»„ä»¶çš„å®Œæ•´ç¯å¢ƒï¼š
```bash
pip install --no-binary=av -e ".[aloha, pusht]"
```

ä½¿ç”¨ [Weights and Biases](https://docs.wandb.ai/quickstart) è¿›è¡Œå®éªŒè¿½è¸ªæ—¶éœ€ç™»å½•ï¼š
```bash
wandb login
```

ï¼ˆæ³¨ï¼šè¿˜éœ€åœ¨é…ç½®ä¸­å¯ç”¨ WandB åŠŸèƒ½ï¼Œè¯¦è§åç»­è¯´æ˜ï¼‰

## Walkthrough

```
.
â”œâ”€â”€ examples             # contains demonstration examples, start here to learn about LeRobot
|   â””â”€â”€ advanced         # contains even more examples for those who have mastered the basics
â”œâ”€â”€ lerobot
|   â”œâ”€â”€ configs          # contains config classes with all options that you can override in the command line
|   â”œâ”€â”€ common           # contains classes and utilities
|   |   â”œâ”€â”€ datasets       # various datasets of human demonstrations: aloha, pusht, xarm
|   |   â”œâ”€â”€ envs           # various sim environments: aloha, pusht, xarm
|   |   â”œâ”€â”€ policies       # various policies: act, diffusion, tdmpc
|   |   â”œâ”€â”€ robot_devices  # various real devices: dynamixel motors, opencv cameras, koch robots
|   |   â””â”€â”€ utils          # various utilities
|   â””â”€â”€ scripts          # contains functions to execute via command line
|       â”œâ”€â”€ eval.py                 # load policy and evaluate it on an environment
|       â”œâ”€â”€ train.py                # train a policy via imitation learning and/or reinforcement learning
|       â”œâ”€â”€ control_robot.py        # teleoperate a real robot, record data, run a policy
|       â”œâ”€â”€ push_dataset_to_hub.py  # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub
|       â””â”€â”€ visualize_dataset.py    # load a dataset and render its demonstrations
â”œâ”€â”€ outputs               # contains results of scripts execution: logs, videos, model checkpoints
â””â”€â”€ tests                 # contains pytest utilities for continuous integration
```

### Visualize datasets

Check out [example 1](./examples/1_load_lerobot_dataset.py) that illustrates how to use our dataset class which automatically downloads data from the Hugging Face hub.

You can also locally visualize episodes from a dataset on the hub by executing our script from the command line:
```bash
python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --episode-index 0
```

or from a dataset in a local folder with the `root` option and the `--local-files-only` (in the following case the dataset will be searched for in `./my_local_data_dir/lerobot/pusht`)
```bash
python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --root ./my_local_data_dir \
    --local-files-only 1 \
    --episode-index 0
```


It will open `rerun.io` and display the camera streams, robot states and actions, like this:

https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240505T172924Z&X-Amz-Expires=300&X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&X-Amz-SignedHeaders=host&actor_id=24889239&key_id=0&repo_id=748713144


Our script can also visualize datasets stored on a distant server. See `python lerobot/scripts/visualize_dataset.py --help` for more instructions.

### The `LeRobotDataset` format

A dataset in `LeRobotDataset` format is very simple to use. It can be loaded from a repository on the Hugging Face hub or a local folder simply with e.g. `dataset = LeRobotDataset("lerobot/aloha_static_coffee")` and can be indexed into like any Hugging Face and PyTorch dataset. For instance `dataset[0]` will retrieve a single temporal frame from the dataset containing observation(s) and an action as PyTorch tensors ready to be fed to a model.

A specificity of `LeRobotDataset` is that, rather than retrieving a single frame by its index, we can retrieve several frames based on their temporal relationship with the indexed frame, by setting `delta_timestamps` to a list of relative times with respect to the indexed frame. For example, with `delta_timestamps = {"observation.image": [-1, -0.5, -0.2, 0]}`  one can retrieve, for a given index, 4 frames: 3 "previous" frames 1 second, 0.5 seconds, and 0.2 seconds before the indexed frame, and the indexed frame itself (corresponding to the 0 entry). See example [1_load_lerobot_dataset.py](examples/1_load_lerobot_dataset.py) for more details on `delta_timestamps`.

Under the hood, the `LeRobotDataset` format makes use of several ways to serialize data which can be useful to understand if you plan to work more closely with this format. We tried to make a flexible yet simple dataset format that would cover most type of features and specificities present in reinforcement learning and robotics, in simulation and in real-world, with a focus on cameras and robot states but easily extended to other types of sensory inputs as long as they can be represented by a tensor.

Here are the important details and internal structure organization of a typical `LeRobotDataset` instantiated with `dataset = LeRobotDataset("lerobot/aloha_static_coffee")`. The exact features will change from dataset to dataset but not the main aspects:

```
dataset attributes:
  â”œ hf_dataset: a Hugging Face dataset (backed by Arrow/parquet). Typical features example:
  â”‚  â”œ observation.images.cam_high (VideoFrame):
  â”‚  â”‚   VideoFrame = {'path': path to a mp4 video, 'timestamp' (float32): timestamp in the video}
  â”‚  â”œ observation.state (list of float32): position of an arm joints (for instance)
  â”‚  ... (more observations)
  â”‚  â”œ action (list of float32): goal position of an arm joints (for instance)
  â”‚  â”œ episode_index (int64): index of the episode for this sample
  â”‚  â”œ frame_index (int64): index of the frame for this sample in the episode ; starts at 0 for each episode
  â”‚  â”œ timestamp (float32): timestamp in the episode
  â”‚  â”œ next.done (bool): indicates the end of en episode ; True for the last frame in each episode
  â”‚  â”” index (int64): general index in the whole dataset
  â”œ episode_data_index: contains 2 tensors with the start and end indices of each episode
  â”‚  â”œ from (1D int64 tensor): first frame index for each episode â€” shape (num episodes,) starts with 0
  â”‚  â”” to: (1D int64 tensor): last frame index for each episode â€” shape (num episodes,)
  â”œ stats: a dictionary of statistics (max, mean, min, std) for each feature in the dataset, for instance
  â”‚  â”œ observation.images.cam_high: {'max': tensor with same number of dimensions (e.g. `(c, 1, 1)` for images, `(c,)` for states), etc.}
  â”‚  ...
  â”œ info: a dictionary of metadata on the dataset
  â”‚  â”œ codebase_version (str): this is to keep track of the codebase version the dataset was created with
  â”‚  â”œ fps (float): frame per second the dataset is recorded/synchronized to
  â”‚  â”œ video (bool): indicates if frames are encoded in mp4 video files to save space or stored as png files
  â”‚  â”” encoding (dict): if video, this documents the main options that were used with ffmpeg to encode the videos
  â”œ videos_dir (Path): where the mp4 videos or png images are stored/accessed
  â”” camera_keys (list of string): the keys to access camera features in the item returned by the dataset (e.g. `["observation.images.cam_high", ...]`)
```

A `LeRobotDataset` is serialised using several widespread file formats for each of its parts, namely:
- hf_dataset stored using Hugging Face datasets library serialization to parquet
- videos are stored in mp4 format to save space
- metadata are stored in plain json/jsonl files

Dataset can be uploaded/downloaded from the HuggingFace hub seamlessly. To work on a local dataset, you can specify its location with the `root` argument if it's not in the default `~/.cache/huggingface/lerobot` location.

### è¯„ä¼°é¢„è®­ç»ƒç­–ç•¥
å‚è€ƒï¼Œè¯¥ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä»Hugging Faceå¹³å°ä¸‹è½½é¢„è®­ç»ƒç­–ç•¥ï¼Œå¹¶åœ¨å¯¹åº”ç¯å¢ƒä¸­è¿è¡Œè¯„ä¼°ã€‚
æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªåŠŸèƒ½æ›´å¼ºå¤§çš„è„šæœ¬ï¼Œå¯åœ¨åŒä¸€è½® rollout è¿‡ç¨‹ä¸­å¹¶è¡Œè¯„ä¼°å¤šä¸ªç¯å¢ƒã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨[lerobot/diffusion_pusht](https://huggingface.co/lerobot/diffusion_pusht)ä¸Šæ‰˜ç®¡çš„é¢„è®­ç»ƒæ¨¡å‹çš„ç¤ºä¾‹ï¼š
```bash
python lerobot/scripts/eval.py \
    --policy.path=lerobot/diffusion_pusht \
    --env.type=pusht \
    --eval.batch_size=10 \
    --eval.n_episodes=10 \
    --policy.use_amp=false \
    --policy.device=cuda
```
æ³¨æ„ï¼šè®­ç»ƒå®Œè‡ªå·±çš„ç­–ç•¥åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤é‡æ–°è¯„ä¼°æ£€æŸ¥ç‚¹ï¼š
```bash
python lerobot/scripts/eval.py --policy.path={OUTPUT_DIR}/checkpoints/last/pretrained_model
```
æ›´å¤šæŒ‡ä»¤è¯·æŸ¥çœ‹`python lerobot/scripts/eval.py --help`ã€‚
### è®­ç»ƒè‡ªå·±çš„ç­–ç•¥
å‚è€ƒ[ç¤ºä¾‹3](./examples/3_train_policy.py)ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„æ ¸å¿ƒPythonåº“è®­ç»ƒæ¨¡å‹ï¼Œä»¥åŠ[ç¤ºä¾‹4](./examples/4_train_policy_with_script.md)ï¼Œäº†è§£å¦‚ä½•é€šè¿‡å‘½ä»¤è¡Œä½¿ç”¨è®­ç»ƒè„šæœ¬ã€‚
å¦‚éœ€ä½¿ç”¨wandbè®°å½•è®­ç»ƒå’Œè¯„ä¼°æ›²çº¿ï¼Œè¯·ç¡®ä¿å·²è¿è¡Œ`wandb login`ä½œä¸ºä¸€æ¬¡æ€§è®¾ç½®æ­¥éª¤ã€‚ç„¶åï¼Œåœ¨è¿è¡Œä¸Šè¿°è®­ç»ƒå‘½ä»¤æ—¶ï¼Œé€šè¿‡æ·»åŠ `--wandb.enable=true`åœ¨é…ç½®ä¸­å¯ç”¨WandBã€‚
ç»ˆç«¯ä¸­è¿˜ä¼šä»¥é»„è‰²æ˜¾ç¤ºwandbæ—¥å¿—çš„é“¾æ¥ã€‚ä»¥ä¸‹æ˜¯æµè§ˆå™¨ä¸­æ—¥å¿—çš„ç¤ºä¾‹ã€‚è¯·åŒæ—¶æŸ¥çœ‹[æ­¤å¤„](./examples/4_train_policy_with_script.md#typical-logs-and-metrics)äº†è§£æ—¥å¿—ä¸­å¸¸ç”¨æŒ‡æ ‡çš„è¯´æ˜ã€‚
æ³¨æ„ï¼šå‡ºäºæ•ˆç‡è€ƒè™‘ï¼Œè®­ç»ƒæœŸé—´æ¯ä¸ªæ£€æŸ¥ç‚¹ä»…ä½¿ç”¨å°‘é‡episodeè¿›è¡Œè¯„ä¼°ã€‚å¯ä»¥ä½¿ç”¨`--eval.n_episodes=500`æ¥å¢åŠ è¯„ä¼°çš„episodeæ•°é‡ã€‚æˆ–è€…ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥é‡æ–°è¯„ä¼°æœ€ä½³æ£€æŸ¥ç‚¹ï¼Œè°ƒæ•´è¯„ä¼°è®¾ç½®ã€‚æ›´å¤šæŒ‡ä»¤è¯·æŸ¥çœ‹`python lerobot/scripts/eval.py --help`ã€‚
#### å¤ç°æœ€å…ˆè¿›ï¼ˆSOTAï¼‰ç»“æœ
æˆ‘ä»¬åœ¨[hubé¡µé¢](https://huggingface.co/lerobot)æä¾›äº†ä¸€äº›é¢„è®­ç»ƒç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥å¯ä»¥è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é€šè¿‡åŠ è½½å…¶è¿è¡Œçš„é…ç½®ï¼Œå¯ä»¥å¤ç°å®ƒä»¬çš„è®­ç»ƒã€‚åªéœ€è¿è¡Œï¼š
```bash
python lerobot/scripts/train.py --config_path=lerobot/diffusion_pusht
```
å³å¯å¤ç°Diffusion Policyåœ¨PushTä»»åŠ¡ä¸Šçš„SOTAç»“æœã€‚
## è´¡çŒ®
å¦‚æœæƒ³ä¸ºğŸ¤— LeRobotåšå‡ºè´¡çŒ®ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](https://github.com/huggingface/lerobot/blob/main/CONTRIBUTING.md)ã€‚
### æ·»åŠ é¢„è®­ç»ƒç­–ç•¥
è®­ç»ƒå®Œç­–ç•¥åï¼Œå¯ä»¥å°†å…¶ä¸Šä¼ åˆ°Hugging Faceå¹³å°ï¼Œä½¿ç”¨ç±»ä¼¼`${hf_user}/${repo_name}`çš„hub idï¼ˆä¾‹å¦‚[lerobot/diffusion_pusht](https://huggingface.co/lerobot/diffusion_pusht)ï¼‰ã€‚
é¦–å…ˆéœ€è¦æ‰¾åˆ°å®éªŒç›®å½•ä¸­çš„æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚`outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500`ï¼‰ã€‚å…¶ä¸­åº”åŒ…å«ä¸€ä¸ª`pretrained_model`ç›®å½•ï¼Œè¯¥ç›®å½•ä¸­åº”æœ‰ä»¥ä¸‹æ–‡ä»¶ï¼š
- `config.json`ï¼šç­–ç•¥é…ç½®çš„åºåˆ—åŒ–ç‰ˆæœ¬ï¼ˆéµå¾ªç­–ç•¥çš„æ•°æ®ç±»é…ç½®ï¼‰ã€‚
- `model.safetensors`ï¼šä¸€ç»„`torch.nn.Module`å‚æ•°ï¼Œä»¥[Hugging Face Safetensors](https://huggingface.co/docs/safetensors/index)æ ¼å¼ä¿å­˜ã€‚
- `train_config.json`ï¼šåŒ…å«æ‰€æœ‰è®­ç»ƒå‚æ•°çš„ç»Ÿä¸€é…ç½®ã€‚ç­–ç•¥é…ç½®åº”ä¸`config.json`å®Œå…¨ä¸€è‡´ã€‚è¿™å¯¹äºè¯„ä¼°ç­–ç•¥æˆ–å¤ç°ç»“æœéå¸¸æœ‰ç”¨ã€‚
å°†è¿™äº›æ–‡ä»¶ä¸Šä¼ åˆ°hubï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
```bash
huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model
```
å‚è€ƒ[eval.py](https://github.com/huggingface/lerobot/blob/main/lerobot/scripts/eval.py)äº†è§£å…¶ä»–äººå¦‚ä½•ä½¿ç”¨ä½ çš„ç­–ç•¥ã€‚
### é€šè¿‡æ€§èƒ½åˆ†æä¼˜åŒ–ä»£ç 
ä»¥ä¸‹æ˜¯ä¸€ä¸ªç”¨äºåˆ†æç­–ç•¥è¯„ä¼°æ€§èƒ½çš„ä»£ç ç‰‡æ®µç¤ºä¾‹ï¼š
```python
from torch.profiler import profile, record_function, ProfilerActivity
def trace_handler(prof):
    prof.export_chrome_trace(f"tmp/trace_schedule_{prof.step_num}.json")
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    schedule=torch.profiler.schedule(
        wait=2,
        warmup=2,
        active=3,
    ),
    on_trace_ready=trace_handler
) as prof:
    with record_function("eval_policy"):
        for i in range(num_episodes):
            prof.step()
            # æ’å…¥éœ€è¦åˆ†æçš„ä»£ç ï¼Œå¯èƒ½æ˜¯eval_policyå‡½æ•°çš„æ•´ä¸ªä¸»ä½“
```
```

## å¼•ç”¨è¯´æ˜
å¦‚æœæ‚¨å¸Œæœ›å¼•ç”¨æœ¬é¡¹ç›®ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
```bibtex
@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = "\url{https://github.com/huggingface/lerobot}",
    year = {2024}
}
```
æ­¤å¤–ï¼Œå¦‚æœæ‚¨ä½¿ç”¨äº†ç‰¹å®šçš„ç­–ç•¥æ¶æ„ã€é¢„è®­ç»ƒæ¨¡å‹æˆ–æ•°æ®é›†ï¼Œå»ºè®®åŒæ—¶å¼•ç”¨åŸå§‹ä½œè€…çš„å·¥ä½œï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰ï¼š
- 
```bibtex
@article{chi2024diffusionpolicy,
	author = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
	title ={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	journal = {The International Journal of Robotics Research},
	year = {2024},
}
```
- [ACT æˆ– ALOHA](https://tonyzhaozh.github.io/aloha)
```bibtex
@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}
```
- [TDMPC](https://www.nicklashansen.com/td-mpc/)
```bibtex
@inproceedings{Hansen2022tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={ICML},
	year={2022}
}
```
- [VQ-BeT](https://sjlee.cc/vq-bet/)
```bibtex
@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}
```
## é¡¹ç›®æ˜Ÿæ ‡å†å²
[](https://star-history.com/#huggingface/lerobot&Timeline)
ï¼ˆæ³¨ï¼šç¿»è¯‘æ—¶ä¿ç•™ä¸“æœ‰æŠ€æœ¯åè¯å¦‚Diffusion Policy/ACT/TDMPCç­‰ä¸è¯‘ï¼›å­¦æœ¯æ–‡çŒ®å¼•ç”¨æ ¼å¼ä¸¥æ ¼éµå¾ªåŸæ–‡ï¼›è¶…é“¾æ¥ä¸å›¾è¡¨ä»£ç æœªä½œæ”¹åŠ¨ä»¥ç¡®ä¿åŠŸèƒ½æ­£å¸¸ï¼‰
